{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network and Deep Learning \n",
    "## Challenge 1: Image Classification\n",
    "### Team:   Bergamasco Alex 10521973\n",
    "\n",
    "This is the first approach that i used in this challenge.\n",
    "I started building a custom CNN performing parameters tuning both in the data augmentation section and in the hyperparameters of the neural network.\n",
    "\n",
    "At the end, I reached a 0.70 accuracy with this model.\n",
    "\n",
    "\n",
    "After this approach, I continued the challenge performing Transfer Learning with different pre-trained models (explained in the other notebook)\n",
    "\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "With some trial and error approach I tuned parameters in the ImageDataGenerator. These are the parameters that I used in my best model.\n",
    "\n",
    "\n",
    "### Creating the CNN\n",
    "\n",
    "I used the same code-structure of the lectures, I found it very useful, principally when I tried to add some dropout and batch normalization layers between blocks.\n",
    "\n",
    "List of actions:\n",
    "- I tried to add some layers but I didn't reach any improvement.\n",
    "- Modify parameters in data augmentation with (a lot of) trial & error technique. Reached 0.56-0.6 accuracy\n",
    "- Changed the image_size (300x300 performs good w.r.t. 256x256) because of the shape of the original images.\n",
    "- Added dropout and batch normalization layers to avoid overfitting and it performed very well, getting a 0.7 of accuracy.\n",
    "\n",
    "There are some intermediate steps that I don't mentioned, related principally to hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import split_folders\n",
    "\n",
    "# Split with a ratio of .8 and .2 (train and validation)\n",
    "split_folders.ratio('/home/alex/Desktop/Keras_Lectures/competition/Classification_Dataset/training', output=\"output\", seed=1337, ratio=(.8, .2)) # default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set true to perform data augmentation\n",
    "data_aug = True\n",
    "\n",
    "if data_aug:\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=30,\n",
    "                                        width_shift_range=0.1,\n",
    "                                        height_shift_range=0.1,\n",
    "                                        shear_range=0.01,\n",
    "                                        zoom_range=[0.9, 1.1],\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=False,\n",
    "                                        fill_mode='reflect',\n",
    "                                        brightness_range=[0.5, 1.5],\n",
    "                                        rescale=1./255)\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(cwd, 'Classification_Dataset')\n",
    "\n",
    "bs = 8\n",
    "\n",
    "# Image Shape\n",
    "img_h = 300\n",
    "img_w = 300\n",
    "\n",
    "num_classes=20\n",
    "\n",
    "input_shape = (img_h, img_w, 3)\n",
    "\n",
    "decide_class_indices = True\n",
    "\n",
    "if decide_class_indices:\n",
    "    classes = [ 'owl',\n",
    "                'galaxy',\n",
    "                'lightning',\n",
    "                'wine-bottle',\n",
    "                't-shirt',\n",
    "                'waterfall',\n",
    "                'sword',\n",
    "                'school-bus',\n",
    "                'calculator',\n",
    "                'sheet-music',\n",
    "                'airplanes',\n",
    "                'lightbulb',\n",
    "                'skyscraper',\n",
    "                'mountain-bike',\n",
    "                'fireworks',\n",
    "                'computer-monitor',\n",
    "                'bear',\n",
    "                'grand-piano',\n",
    "                'kangaroo',\n",
    "                'laptop']  \n",
    "else:\n",
    "    classes=None\n",
    "\n",
    "\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_gen = train_data_gen.flow_from_directory(training_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               classes=classes,\n",
    "                                               target_size=(img_h, img_w),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               seed=SEED)  \n",
    "\n",
    "\n",
    "validation_dir = os.path.join(dataset_dir, 'validation')\n",
    "valid_gen = valid_data_gen.flow_from_directory(validation_dir,\n",
    "                                               batch_size=bs, \n",
    "                                               classes=classes,\n",
    "                                               target_size=(img_h, img_w),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and validation dataset from the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the CNN\n",
    "\n",
    "I used the same code-structure of the lectures, I found it very useful, principally when I tried to add some dropout and batch normalization layers between blocks.\n",
    "\n",
    "List of actions:\n",
    "- I tried to add some layers but I didn't reach any improvement.\n",
    "- Modify parameters in data augmentation with (a lot of) trial & error technique. Reached 0.56-0.6 accuracy\n",
    "- Changed the image_size (300x300 performs good w.r.t. 256x256) because of the shape of the original images.\n",
    "- Added dropout and batch normalization layers to avoid overfitting and it performed very well, getting a 0.7 of accuracy.\n",
    "\n",
    "There are some intermediate steps that I don't mentioned, related principally to hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv2d = tf.keras.layers.Conv2D(filters=num_filters,\n",
    "                                             kernel_size=(3, 3),\n",
    "                                             strides=(1, 1), \n",
    "                                             padding='same')\n",
    "        self.activation = tf.keras.layers.ReLU()\n",
    "        self.batchnormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.pooling = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2) \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv2d(inputs)\n",
    "        x = self.activation(x)\n",
    "        x = self.batchnormalization(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 5\n",
    "start_f = 8\n",
    "num_classes = 20\n",
    "\n",
    "class CNNClassifier(tf.keras.Model):\n",
    "    def __init__(self, depth, start_f, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = tf.keras.Sequential()\n",
    "    \n",
    "        for i in range(depth):\n",
    "            self.feature_extractor.add(ConvBlock(num_filters=start_f))\n",
    "            start_f *= 2\n",
    "            \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.classifier = tf.keras.Sequential()\n",
    "        self.classifier.add(tf.keras.layers.Dense(units=512, activation='relu', kernel_initializer='he_uniform'))\n",
    "        self.classifier.add(tf.keras.layers.BatchNormalization())\n",
    "        self.classifier.add(tf.keras.layers.Dropout(0.4)) \n",
    "        self.classifier.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.feature_extractor(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CNNClassifier(depth=depth,\n",
    "                      start_f=start_f,\n",
    "                      num_classes=num_classes)\n",
    "\n",
    "model.build(input_shape=(None, img_h, img_w, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_extractor.summary()\n",
    "model.summary()\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_dataset,\n",
    "          epochs=60,\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "test_dir = os.path.join(cwd, 'Classification_Dataset/test')\n",
    "image_filenames = next(os.walk(test_dir))[2]\n",
    "\n",
    "results = {}\n",
    "for image_name in image_filenames:\n",
    "    img = Image.open(os.path.join(test_dir,'{}').format(image_name)).convert('RGB')\n",
    "    img = img.resize((img_h, img_w))\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, 0) \n",
    "    \n",
    "    out_softmax = model.predict(x=img_array / 255.)\n",
    "    \n",
    "    predicted_class = np.argmax(out_softmax, -1)\n",
    "    \n",
    "    predicted_class = predicted_class[0]\n",
    "    \n",
    "    results[image_name] = predicted_class\n",
    " \n",
    "create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_cpu)",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
