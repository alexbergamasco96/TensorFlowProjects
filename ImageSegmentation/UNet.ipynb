{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation - 2nd Challenge\n",
    "\n",
    "## UNet Architecture\n",
    "\n",
    "In this notebook we create an architecture based on UNet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Main aspects:\n",
    "- Skip connections between the encoder and the decoder\n",
    "- Dice loss implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "if apply_data_augmentation:\n",
    "    train_img_data_gen = ImageDataGenerator(featurewise_center=True,\n",
    "                                            featurewise_std_normalization=True,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            rescale=1./255,\n",
    "                                            validation_split=0.2)\n",
    "    train_mask_data_gen = ImageDataGenerator(featurewise_center=True,\n",
    "                                             featurewise_std_normalization=True,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             rescale=1./255,\n",
    "                                             validation_split=0.2)\n",
    "else:\n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    train_mask_data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/kaggle/input/ann-and-dl-image-segmentation/Segmentation_Dataset\"\n",
    "\n",
    "# Batch size\n",
    "bs = 8\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "\n",
    "#------------------- TRAINING DATASET ---------------------\n",
    "\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, \n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       #color_mode = 'rgb',\n",
    "                                                       subset='training')  \n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, \n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         color_mode='grayscale',\n",
    "                                                         subset='training')\n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "\n",
    "\n",
    "\n",
    "#------------------- VALIDATION DATASET ---------------------\n",
    "\n",
    "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, \n",
    "                                                       shuffle=False,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       #color_mode = 'rgb',\n",
    "                                                       subset='validation')\n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs, \n",
    "                                                         class_mode=None, \n",
    "                                                         shuffle=False,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         color_mode='grayscale',\n",
    "                                                         subset='validation')\n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(y_, tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "\n",
    "#------------------- TRAINING DATASET ---------------------\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "\n",
    "\n",
    "#------------------- VALIDATION DATASET ---------------------\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# Main structure:\n",
    "#   - Conv2D\n",
    "#   - BatchNorm\n",
    "#   - ReLU\n",
    "\n",
    "\n",
    "# ----- ENCODER\n",
    "def encoder_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    c = keras.layers.BatchNormalization()(c)\n",
    "    c = keras.layers.ReLU()(c)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(c)\n",
    "    c = keras.layers.BatchNormalization()(c)\n",
    "    c = keras.layers.ReLU()(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "\n",
    "\n",
    "# ----- DECODER\n",
    "def decoder_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(concat)\n",
    "    c = keras.layers.BatchNormalization()(c)\n",
    "    c = keras.layers.ReLU()(c)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(c)\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "# ----- BOTTOM\n",
    "def bottom_layer(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    c = keras.layers.BatchNormalization()(c)\n",
    "    c = keras.layers.ReLU()(c)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    \n",
    "    #Filters\n",
    "    f = [8, 16, 32, 64, 128, 256]\n",
    "    \n",
    "    #Input\n",
    "    inputs = keras.layers.Input((img_h, img_w, 3))\n",
    "    \n",
    "    p0 = inputs\n",
    "    \n",
    "    ### --- ENCODER  ###\n",
    "    c1, p1 = encoder_block(p0, f[0]) \n",
    "    c2, p2 = encoder_block(p1, f[1]) \n",
    "    c3, p3 = encoder_block(p2, f[2])\n",
    "    c4, p4 = encoder_block(p3, f[3]) \n",
    "    c5, p5 = encoder_block(p4, f[4])\n",
    "    \n",
    "    \n",
    "    bn = bottom_layer(p5, f[5])\n",
    "    \n",
    "    \n",
    "    ### --- DECODER --- ###\n",
    "    u0 = decoder_block(bn, c5, f[4])\n",
    "    u1 = decoder_block(u0, c4, f[3]) \n",
    "    u2 = decoder_block(u1, c3, f[2]) \n",
    "    u3 = decoder_block(u2, c2, f[1]) \n",
    "    u4 = decoder_block(u3, c1, f[0]) \n",
    "    \n",
    "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Intersection over Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_IoU(y_true, y_pred):\n",
    "    \n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) \n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    \n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "model = UNet()\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-3), loss=dice_coef_loss, metrics=[my_IoU])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_dataset,\n",
    "          epochs=30,\n",
    "          steps_per_epoch=len(train_img_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_img_gen)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(csv_fname, 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "test_dir = \"/kaggle/input/ann-and-dl-image-segmentation/Segmentation_Dataset/test\"\n",
    "test_img_dir = os.path.join(test_dir, 'images/img')\n",
    "\n",
    "img_filenames = next(os.walk(test_img_dir))[2]\n",
    "results = {}\n",
    "\n",
    "for image_name in img_filenames:\n",
    "    img = Image.open(os.path.join(test_img_dir,'{}').format(image_name)).convert('RGB')\n",
    "    img = img.resize((img_h, img_w))\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, 0) \n",
    "    \n",
    "    out = model.predict(x=img_array / 255.)\n",
    "    \n",
    "    out = np.round(out)\n",
    "    \n",
    "    predicted = rle_encode(out)\n",
    "    \n",
    "    name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    results[name] = predicted\n",
    " \n",
    "create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
